---
title: "p8105_hw2_af3341"
author: "Alana Ferris"
date: "2022-09-29"
output: github_document
---

```{r, message = FALSE}
library(tidyverse)
library(dplyr)
library(readxl)
```

# Problem 1 

```{r, message = FALSE}
transit_df = read_csv("data/NYC_transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) %>%
  mutate_at(c("route8", "route9", "route10", "route11"), as.character)
```

## Dataset Description
The NYC Transit dataset contains `r nrow(transit_df)` observations of individual New York City subway entrances and/or exits. The `r ncol(transit_df)` variables selected for include: the name of the transit line; the station name; the latitude and longitude of that station; the routes the line services; whether or not the station exits are also entrances; the type of entrance (stair, elevator, etc.); if it is an accessible entrance; and if there is a vending machine at that station.
To clean the data, first we used the `clean_names` function from the  `janitor` package to make every variable name lowercase and snake_case. Then, we selected for the variables of interest, which are listed above. Next, we mutated some of the route variables so they were all character variables. The resulting data set has the dimensions described above: 1,868 rows by 19 columns. However, this data set is not tidy because not all the columns are variables--`route_num` should be a variable. To tidy the data then, we would need to use `pivot_longer` to make `route_num` into a variable.

## How Many Distinct Stations? 

```{r}
distinct_station_df = transit_df %>%
  group_by(station_name) %>%
  distinct(line)
```

There are 465 distinct stations. 

## How Many Stations Are ADA Compliant?

```{r}
ADA_compliant_df = transit_df %>%
  filter(ada == TRUE)

station_ada_df = ADA_compliant_df  %>%
  group_by(station_name) %>%
  distinct(line)
```

There are 84 ADA compliant distinct stations in this data set. 

## What is the Proportion of Stations Without Vending Machines That Also Have Entrances?

```{r}
no_vending_df = transit_df %>%
  filter(vending == "NO") 

entry_no_vending_df = no_vending_df %>%
  filter(entry == TRUE)

nrow(entry_no_vending_df)/nrow(no_vending_df)
```

About 37.7% of stations that do not have vending machines also have entrances.

## Reformatting Data

```{r}
distinct_A_df = transit_df %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line, ada) %>% 
  distinct()

ADA_A_df = distinct_A_df %>% 
  filter(ada == TRUE)
```

There are 60 distinct stations that serve the A train, and of those there are 17 that are ADA compliant. 

# Problem 2

## mr_trash_wheel dataframe

```{r, warning = FALSE}
mr_trash_wheel = read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:O550") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate_at(vars(sports_balls), funs(round(., 0))) %>% 
  mutate_at(c("sports_balls"), as.integer) %>% 
  mutate_at(c("dumpster"), as.double) %>% 
  mutate_at(c("year"), as.double)
```

## prof_trash_wheel dataframe
```{r}
prof_trash_wheel = read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:N97") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster)
```

## Joining Data Sets

```{r}
both_trash_wheels = 
  bind_rows(mr_trash_wheel, prof_trash_wheel)
```

## Dataset Description

The `both_trash_wheels` dataset contains `r nrow(both_trash_wheels)` observations of dumpster fills of 2 different trash wheels: Mr. Trash Wheel and Professor Trash Wheel. The different dumpster metrics include `r ncol(both_trash_wheels)` variables, like: the name of the trash wheel; the weight and volume of trash collected; the number of dumpsters filled; the date the full dumpster was collected; the different types of trash collected; and the homes powered from the incineration of the dumpsters. For example, the total weight of trash collected by Professor Trashweel from January 2017 to July 2022 was `r sum(prof_trash_wheel$weight_tons)` tons. Additionally, the total number of sports balls collected by Mr. Trash Wheel in 2020 was `r aggregate(sports_balls ~ year, data = mr_trash_wheel, sum) %>% filter(year == 2020) %>% magrittr::extract2("sports_balls")` balls. 

# Problem 3

## Cleaning pols_month_df

```{r, message = FALSE, warning = FALSE}
pols_month_df = read_csv('data/pols-month.csv') %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), convert = TRUE) %>% 
  mutate(month = recode(month, `1` = "jan", `2` = "feb", `3` = "mar", `4` = "apr", `5` = "may", `6` = "jun", `7` = "jul", `8` = "aug", `9` = "sep", `10` = "oct", `11` = "nov", `12` = "dec")) %>% 
  select(year, month, -day, prez_gop, prez_dem, gov_gop, gov_dem, sen_gop, sen_dem, rep_gop, rep_dem) %>% 
  mutate(prez_gop = recode(prez_gop, `1` = "gop", `0` = "dem")) %>% 
  mutate(prez_dem = recode(prez_dem, `1` = "dem", `0` = "gop")) %>% 
pivot_longer(
    prez_gop:prez_dem,
    values_to = "president") %>% 
  select(-name)
```

## Cleaning snp_df

```{r, message = FALSE, warning = FALSE}
snp_df = read_csv('data/snp.csv') %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), convert = TRUE) %>%
  mutate(month = recode(month, `1` = "jan", `2` = "feb", `3` = "mar", `4` = "apr", `5` = "may", `6` = "jun", `7` = "jul", `8` = "aug", `9` = "sep", `10` = "oct", `11` = "nov", `12` = "dec")) %>% 
  mutate(year90s = year + 1900) %>%
  mutate(year00s = year + 2000) %>%
  mutate(year_new = case_when(year > 45 ~ year90s,
                          T ~ year00s)) %>%
  select(year = year_new, month, -day, close)
```

## Cleaning unemployment_df

```{r, message = FALSE, warning = FALSE}
unemployment_df = read_csv("data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_rate")
```

## Joining Datasets

```{r, message = FALSE, warning = FALSE}
snp_pols_df = 
  full_join(snp_df, pols_month_df)

all_3_df = 
  full_join(snp_pols_df, unemployment_df)
```

## Merged Dataset Description

I merged 3 datasets to create the `all_3_df` data set. The `snp_df` contained `r nrow(snp_df)` observations of closing values of the S&P stock index on associated dates. The `pols_month_df` contained `r nrow(pols_month_df)` observations of which political party was in control in federal, state, and local governments. The `unemployment_df` contained `r nrow(unemployment_df)` observations of the rate of unemployment during associated years. After combining them into the `all_3_df`, the merged data set contains `r nrow(all_3_df)` observations of which political party was in control (democratic or republican) between the months and years of January 1947 and December 2015. There are `r ncol(all_3_df)` total variables that detail presidential, senatorial, house of representatives, and gubernatorial political affiliations, as well as the corresponding unemployment rates and closing values of the S&P stock index on the associated date.  
